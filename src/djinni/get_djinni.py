from enum import Enum
import random
from typing import List, TypedDict
import requests
import re
import urllib.request
from bs4 import BeautifulSoup


from djinni.vacancies_djinni_source import VacanciesDjinniSource
from vacancy_types.vacancies_scrap_type import VacanciesScrapType


class ValidEnum(Enum):
    @staticmethod
    def is_valid(value):
        return value in ValidEnum._value2member_map_


class Language(ValidEnum):
    NoEnglish = "No English"
    BeginnerElementary = "Beginner/Elementary"
    PreIntermediate = "Pre-Intermediate"
    Intermediate = "Intermediate"
    UpperIntermediate = "Upper-Intermediate"
    AdvancedFluent = "Advanced/Fluent"


class Experience(ValidEnum):
    –ë–µ–∑–¥–æ—Å–≤—ñ–¥—É = "–ë–µ–∑ –¥–æ—Å–≤—ñ–¥—É"
    —Ä—ñ–∫1 = "1 —Ä—ñ–∫"
    —Ä–æ–∫–∏2 = "2 —Ä–æ–∫–∏"
    —Ä–æ–∫–∏3 = "3 —Ä–æ–∫–∏"
    —Ä–æ–∫–∏4 = "4 —Ä–æ–∫–∏"
    —Ä–æ–∫—ñ–≤5 = "5 —Ä–æ–∫—ñ–≤"
    —Ä–æ–∫—ñ–≤6 = "6 —Ä–æ–∫—ñ–≤"
    —Ä–æ–∫—ñ–≤7 = "7 —Ä–æ–∫—ñ–≤"
    —Ä–æ–∫—ñ–≤8 = "8 —Ä–æ–∫—ñ–≤"
    —Ä–æ–∫—ñ–≤9 = "9 —Ä–æ–∫—ñ–≤"
    —Ä–æ–∫—ñ–≤_—Ç–∞_–±—ñ–ª—å—à–µ10 = "10 —Ä–æ–∫—ñ–≤ —Ç–∞ –±—ñ–ª—å—à–µ"


class Employment(ValidEnum):
    –í—ñ–¥–¥–∞–ª–µ–Ω–∞_—Ä–æ–±–æ—Ç–∞ = "–í—ñ–¥–¥–∞–ª–µ–Ω–∞ —Ä–æ–±–æ—Ç–∞"
    Part_time = "Part-time"
    –û—Ñ—ñ—Å = "–û—Ñ—ñ—Å"


class Region(ValidEnum):
    –£–∫—Ä–∞—ó–Ω–∞ = "–£–∫—Ä–∞—ó–Ω–∞"
    –ö—Ä–∞—ó–Ω–∏_–Ñ–° = "–ö—Ä–∞—ó–Ω–∏ –Ñ–°"
    –Ü–Ω—à—ñ_–∫—Ä–∞—ó–Ω–∏ = "–Ü–Ω—à—ñ –∫—Ä–∞—ó–Ω–∏"


class Editorial(ValidEnum):
    –í–∫–∞–∑–∞–Ω–∞_–∑–∞—Ä–ø–ª–∞—Ç–Ω–∞_–≤–∏–ª–∫–∞ = "–í–∫–∞–∑–∞–Ω–∞ –∑–∞—Ä–ø–ª–∞—Ç–Ω–∞ –≤–∏–ª–∫–∞"
    Ukrainian_Product = "Ukrainian Product üá∫üá¶"
    MilTech = "MilTech ü™ñ"
    Mobilisation_Reservation = "Mobilisation reservation ‚è≥"


class JobRequirements(TypedDict):
    language: Language | None 
    experience: Experience | None
    employment: Employment| None
    region: Region| None
    editorial: Editorial| None


class GetVacanciesDjinni(VacanciesDjinniSource):
    async def get_djinni_vacancies(self, url: str) -> List[VacanciesScrapType]:
        try:
            USER_AGENTS = [
                "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
                "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36",
                "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/118.0.0.0 Safari/537.36",
            ]
            headers = {
                "User-Agent": random.choice(USER_AGENTS),
                "Referer": "https://jobs.dou.ua/",
                "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8",
            }
            response = requests.get(
                url, headers=headers, proxies=urllib.request.getproxies()
            )
            response.raise_for_status()
        except requests.exceptions.RequestException as e:
            print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–∏ –∑–∞–ø—Ä–æ—Å–∞: {e}")
            return []

        soup = BeautifulSoup(response.content, "html.parser")
        pattern = re.compile(r"^job-item-\d+$")
        arr_varancie = []
        for item in soup.find_all("li", id=pattern):
            title_element = item.find(class_="job-item__title-link")
            title = title_element.text.strip() if title_element else ""

            description_element = item.find(class_="js-truncated-text")
            description = (
                description_element.text.strip() if description_element else ""
            )

            link = title_element.get("href") if title_element else ""
            print("work")
            company_element = item.find(class_="text-body js-analytics-event")
            company = company_element.text.strip() if company_element else ""
            company_link = company_element.get("href") if company_element else ""

            company_img_element = item.find(class_="userpic-image userpic-image_img")
            company_img = company_img_element.get("src") if company_img_element else ""

            salary_element = item.find(class_="text-success text-nowrap")
            salary = salary_element.text.strip() if salary_element else ""
            # this i need upgrade
            info_section = item.find(
                class_="fw-medium d-flex flex-wrap align-items-center gap-1"
            )
            self.get_parametr(info_section)
            print(info_section)
            location_element = (
                info_section.find(class_="text-nowrap") if info_section else None
            )
            location = location_element.text.strip() if location_element else ""

            company = getattr(
                item.find(class_="fw-medium d-flex flex-wrap align-items-center gap-1"),
                "text",
                "",
            )

            varancie_djinni: VacanciesScrapType = {
                "title": title,
                "description": description,
                "link": f"https://djinni.co{link}",
                "location": location,
                "company": company,
                "company_img": company_img,
                "company_link": company_link,
                "salary": salary,
            }
            arr_varancie.append(varancie_djinni)
        return arr_varancie

    def get_parametr(self, medium_div):
        jobRequirements: JobRequirements={
             "language":  None,     
             "experience":  None, 
             "employment":  None,  
             "region":  None,          
             "editorial":  None    
        }
        field_checks = {
            "language": Language,
            "experience": Experience,
            "employment": Employment,
            "region": Region,
            "editorial": Editorial
        }
        for span in medium_div.find_all("span", class_="text-nowrap"):
            result = span.get_text(strip=True)
            for field, FieldClass in field_checks.items():
                if FieldClass.is_valid(result):
                    jobRequirements[field] = FieldClass(result).value
        return jobRequirements
